{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6556dccc",
   "metadata": {},
   "source": [
    "# Lending Club Data\n",
    "The Lending Club has made an anonymized set of data available for anyone to study or if you do not have a lending club account the data is also available on Kaggle. \n",
    "\n",
    "The Lending Club is a platform which allows the crowdfunding of various loans. Various investors are able to browse the profiles of people applying for loans and decide whether or not to help fun them.\n",
    "\n",
    "In this assignment you will build a model that predicts the largest loan amount that will be successfully funded for any given individual. This model can then be used to advise the applicants on how much they could apply for.\n",
    "\n",
    "## Cleaning the data\n",
    "### Cleaning Rejected Data Stats\n",
    "Here, I am dropping unnecessary variables such as policy code, application date, states and zipcode variable when I am cleaning the data. There are differences in net income and credits between different states in the States, however, first of all, zip codes are not a number that is aligned from poorest neighborhood to richest neighborhood. It does not mean that zipcode with small number has smaller income compared to larger number zipcode. And also, even if I want it to be used as categorical variable, it only contains the first 3 numbers of the zipcode rather than the whole, which makes categorization of each neighborhood hard. Secondly, each state variable has been removed because from given data, I didn't wanted to discriminate people from where they come from. They may have come from lower credibility state, but they may have important reason to get the money. Consider A and B came to the bank to get lones, and all the things are the same except for A came from a very credible state and B doesn't, B won't get the loans. (Trying to have ethics while making money)\n",
    "Lastly, I tried to contain the Loan title variable as it is the reason why the borrower wants to make the loan, however, there were just too many reasons(73929 unique values) and it just seemed training will take forever in my local. So, for the sake of the assignment, I also dropped the column. \n",
    "\n",
    "### Cleaning the Accepted Data Stats\n",
    "As the assignment instruction states, there are so many information and missing information in the accepted data. Here, I am going to drop the columns that has too much missing values even if it seems relevent when screening the potential loan-er while I drop variables(columns) that are unnecessary. Also, some columns just seemed redundant which dependes purely on duration of time (30days,90days,120days, etc) so I dropped them and left 1 of each unique that seemed more important to me. The reason behind this is that having this much specificity might cause overfitting the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe77a894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\green\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (0,19,49,59,118,129,130,131,134,135,136,139,145,146,147) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pystan\n",
    "import scipy.stats as sts\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#first, manually download the csv file\n",
    "#then upload it in the codes\n",
    "data_reject = pd.read_csv(r'C:\\Users\\green\\Desktop\\2022 Spring\\CS156\\Assignment2\\rejected_2007_to_2018Q4.csv')\n",
    "data_accept = pd.read_csv(r'C:\\Users\\green\\Desktop\\2022 Spring\\CS156\\Assignment2\\accepted_2007_to_2018Q4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bec8215b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Amount Requested Application Date                        Loan Title  \\\n",
      "0            1000.0       2007-05-26  Wedding Covered but No Honeymoon   \n",
      "1            1000.0       2007-05-26                Consolidating Debt   \n",
      "2           11000.0       2007-05-27       Want to consolidate my debt   \n",
      "3            6000.0       2007-05-27                           waksman   \n",
      "4            1500.0       2007-05-27                            mdrigo   \n",
      "\n",
      "   Risk_Score Debt-To-Income Ratio Zip Code State Employment Length  \\\n",
      "0       693.0                  10%    481xx    NM           4 years   \n",
      "1       703.0                  10%    010xx    MA          < 1 year   \n",
      "2       715.0                  10%    212xx    MD            1 year   \n",
      "3       698.0               38.64%    017xx    MA          < 1 year   \n",
      "4       509.0                9.43%    209xx    MD          < 1 year   \n",
      "\n",
      "   Policy Code  \n",
      "0          0.0  \n",
      "1          0.0  \n",
      "2          0.0  \n",
      "3          0.0  \n",
      "4          0.0  \n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount Requested</th>\n",
       "      <th>Loan Title</th>\n",
       "      <th>Risk_Score</th>\n",
       "      <th>Debt-To-Income Ratio</th>\n",
       "      <th>Employment Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>Wedding Covered but No Honeymoon</td>\n",
       "      <td>693.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>Consolidating Debt</td>\n",
       "      <td>703.0</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11000.0</td>\n",
       "      <td>Want to consolidate my debt</td>\n",
       "      <td>715.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1 year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>waksman</td>\n",
       "      <td>698.0</td>\n",
       "      <td>38.64</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>mdrigo</td>\n",
       "      <td>509.0</td>\n",
       "      <td>9.43</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Amount Requested                        Loan Title  Risk_Score  \\\n",
       "0            1000.0  Wedding Covered but No Honeymoon       693.0   \n",
       "1            1000.0                Consolidating Debt       703.0   \n",
       "2           11000.0       Want to consolidate my debt       715.0   \n",
       "3            6000.0                           waksman       698.0   \n",
       "4            1500.0                            mdrigo       509.0   \n",
       "\n",
       "  Debt-To-Income Ratio Employment Length  \n",
       "0                   10           4 years  \n",
       "1                   10          < 1 year  \n",
       "2                   10            1 year  \n",
       "3                38.64          < 1 year  \n",
       "4                 9.43          < 1 year  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's clean the data!\n",
    "#Data cleaning: data_reject\n",
    "print(data_reject.head())\n",
    "#debt to income ratio seems to have '%' symbol that I don't want\n",
    "#remove the symbol\n",
    "data_reject['Debt-To-Income Ratio'] = data_reject['Debt-To-Income Ratio'].str.replace('%','')\n",
    "print('---')\n",
    "#now the data seems to have un-necessary rows that ain't gonna do any help with the assignment\n",
    "#such as 'zip code', 'state', 'policy code'\n",
    "data_reject.drop(['Policy Code'],axis=1,inplace=True)\n",
    "data_reject.drop(['Zip Code'], axis=1, inplace = True)\n",
    "data_reject.drop(['State'], axis=1,inplace=True)\n",
    "data_reject.drop(['Application Date'], axis=1, inplace=True)\n",
    "data_reject.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20ac36d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1000.  11000.   6000. ...  73825. 114800.  64075.] ['Wedding Covered but No Honeymoon' 'Consolidating Debt'\n",
      " 'Want to consolidate my debt' ... 'dougie03' 'freeup'\n",
      " 'Business Advertising Loan'] ['4 years' '< 1 year' '1 year' '3 years' '2 years' '10+ years' '9 years'\n",
      " '5 years' '7 years' '6 years' '8 years' nan]\n",
      "3640\n",
      "73929\n",
      "12\n",
      "                      Percent Missing in Rejected\n",
      "Amount Requested                         0.000000\n",
      "Loan Title                               0.004713\n",
      "Risk_Score                              66.902251\n",
      "Debt-To-Income Ratio                     0.000000\n",
      "Employment Length                        3.440862\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount Requested</th>\n",
       "      <th>Loan Title</th>\n",
       "      <th>Debt-To-Income Ratio</th>\n",
       "      <th>Employment Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>Wedding Covered but No Honeymoon</td>\n",
       "      <td>10</td>\n",
       "      <td>4 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>Consolidating Debt</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11000.0</td>\n",
       "      <td>Want to consolidate my debt</td>\n",
       "      <td>10</td>\n",
       "      <td>1 year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>waksman</td>\n",
       "      <td>38.64</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>mdrigo</td>\n",
       "      <td>9.43</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Amount Requested                        Loan Title Debt-To-Income Ratio  \\\n",
       "0            1000.0  Wedding Covered but No Honeymoon                   10   \n",
       "1            1000.0                Consolidating Debt                   10   \n",
       "2           11000.0       Want to consolidate my debt                   10   \n",
       "3            6000.0                           waksman                38.64   \n",
       "4            1500.0                            mdrigo                 9.43   \n",
       "\n",
       "  Employment Length  \n",
       "0           4 years  \n",
       "1          < 1 year  \n",
       "2            1 year  \n",
       "3          < 1 year  \n",
       "4          < 1 year  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now what are the unique values?\n",
    "Request_reject_unique = data_reject['Amount Requested'].unique()\n",
    "LoanReason_reject_unique = data_reject['Loan Title'].unique()\n",
    "EmployLength_reject_unique=data_reject['Employment Length'].unique()\n",
    "print(Request_reject_unique, LoanReason_reject_unique,EmployLength_reject_unique) \n",
    "#the result shows that there are 12 unique values for employment length\n",
    "#however, we still do not know how many unique reasons exist for other columns\n",
    "print(len(Request_reject_unique))\n",
    "print(len(LoanReason_reject_unique))\n",
    "print(len(EmployLength_reject_unique))\n",
    "#Let's see if there are enough information to use from the chosen columns\n",
    "reject_missing = data_reject.isnull().sum()*100/len(data_reject) #percentage of missing data\n",
    "reject_missing_df = pd.DataFrame({'Percent Missing in Rejected':reject_missing})\n",
    "print(reject_missing_df)\n",
    "#since 'Risk Score' have a lot of data missing from, it seems unreasonable to have that column\n",
    "data_reject.drop(['Risk_Score'], axis=1,inplace=True)\n",
    "data_reject.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1e63125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
      "0  68407277        NaN     3600.0       3600.0           3600.0   36 months   \n",
      "1  68355089        NaN    24700.0      24700.0          24700.0   36 months   \n",
      "2  68341763        NaN    20000.0      20000.0          20000.0   60 months   \n",
      "3  66310712        NaN    35000.0      35000.0          35000.0   60 months   \n",
      "4  68476807        NaN    10400.0      10400.0          10400.0   60 months   \n",
      "\n",
      "   int_rate  installment grade sub_grade  ... hardship_payoff_balance_amount  \\\n",
      "0     13.99       123.03     C        C4  ...                            NaN   \n",
      "1     11.99       820.28     C        C1  ...                            NaN   \n",
      "2     10.78       432.66     B        B4  ...                            NaN   \n",
      "3     14.85       829.90     C        C5  ...                            NaN   \n",
      "4     22.45       289.91     F        F1  ...                            NaN   \n",
      "\n",
      "  hardship_last_payment_amount disbursement_method  debt_settlement_flag  \\\n",
      "0                          NaN                Cash                     N   \n",
      "1                          NaN                Cash                     N   \n",
      "2                          NaN                Cash                     N   \n",
      "3                          NaN                Cash                     N   \n",
      "4                          NaN                Cash                     N   \n",
      "\n",
      "  debt_settlement_flag_date settlement_status settlement_date  \\\n",
      "0                       NaN               NaN             NaN   \n",
      "1                       NaN               NaN             NaN   \n",
      "2                       NaN               NaN             NaN   \n",
      "3                       NaN               NaN             NaN   \n",
      "4                       NaN               NaN             NaN   \n",
      "\n",
      "  settlement_amount settlement_percentage settlement_term  \n",
      "0               NaN                   NaN             NaN  \n",
      "1               NaN                   NaN             NaN  \n",
      "2               NaN                   NaN             NaN  \n",
      "3               NaN                   NaN             NaN  \n",
      "4               NaN                   NaN             NaN  \n",
      "\n",
      "[5 rows x 151 columns]\n",
      "                       Percent Missing in Accepted\n",
      "id                                         0.00000\n",
      "member_id                                100.00000\n",
      "loan_amnt                                  0.00146\n",
      "funded_amnt                                0.00146\n",
      "funded_amnt_inv                            0.00146\n",
      "...                                            ...\n",
      "settlement_status                         98.48516\n",
      "settlement_date                           98.48516\n",
      "settlement_amount                         98.48516\n",
      "settlement_percentage                     98.48516\n",
      "settlement_term                           98.48516\n",
      "\n",
      "[151 rows x 1 columns]\n",
      "[ 3600. 24700. 20000. ...   925.   550.   850.] ['Debt consolidation' 'Business' nan ... 'takeitaway' 'Creditt Card Loan'\n",
      " 'debt reduction/hone updates'] ['10+ years' '3 years' '4 years' '6 years' '1 year' '7 years' '8 years'\n",
      " '5 years' '2 years' '9 years' '< 1 year' nan]\n",
      "1573\n",
      "63156\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "#Let's do the same process with data_accept\n",
    "print(data_accept.head()) #what? 151 columns? dang this is loooong\n",
    "#see the labels\n",
    "#1. See the columns that have too much missing data\n",
    "accepted_missing = data_accept.isnull().sum()*100/len(data_accept)\n",
    "accepted_missing_df = pd.DataFrame({'Percent Missing in Accepted':accepted_missing})\n",
    "print(accepted_missing_df)\n",
    "#e. Find the unique values\n",
    "Request_accept_unique = data_accept['loan_amnt'].unique()\n",
    "LoanReason_accept_unique = data_accept['title'].unique()\n",
    "EmployLength_accept_unique=data_accept['emp_length'].unique()\n",
    "print(Request_accept_unique, LoanReason_accept_unique,EmployLength_accept_unique) \n",
    "print(len(Request_accept_unique))\n",
    "print(len(LoanReason_accept_unique))\n",
    "print(len(EmployLength_accept_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0a4f9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>Loan Title</th>\n",
       "      <th>dti</th>\n",
       "      <th>emp_1 year</th>\n",
       "      <th>emp_10+ years</th>\n",
       "      <th>emp_2 years</th>\n",
       "      <th>emp_3 years</th>\n",
       "      <th>emp_4 years</th>\n",
       "      <th>emp_5 years</th>\n",
       "      <th>emp_6 years</th>\n",
       "      <th>emp_7 years</th>\n",
       "      <th>emp_8 years</th>\n",
       "      <th>emp_9 years</th>\n",
       "      <th>emp_&lt; 1 year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>Wedding Covered but No Honeymoon</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>Consolidating Debt</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11000.0</td>\n",
       "      <td>Want to consolidate my debt</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>waksman</td>\n",
       "      <td>38.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>mdrigo</td>\n",
       "      <td>9.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt                        Loan Title    dti  emp_1 year  \\\n",
       "0     1000.0  Wedding Covered but No Honeymoon     10           0   \n",
       "1     1000.0                Consolidating Debt     10           0   \n",
       "2    11000.0       Want to consolidate my debt     10           1   \n",
       "3     6000.0                           waksman  38.64           0   \n",
       "4     1500.0                            mdrigo   9.43           0   \n",
       "\n",
       "   emp_10+ years  emp_2 years  emp_3 years  emp_4 years  emp_5 years  \\\n",
       "0              0            0            0            1            0   \n",
       "1              0            0            0            0            0   \n",
       "2              0            0            0            0            0   \n",
       "3              0            0            0            0            0   \n",
       "4              0            0            0            0            0   \n",
       "\n",
       "   emp_6 years  emp_7 years  emp_8 years  emp_9 years  emp_< 1 year  \n",
       "0            0            0            0            0             0  \n",
       "1            0            0            0            0             1  \n",
       "2            0            0            0            0             0  \n",
       "3            0            0            0            0             1  \n",
       "4            0            0            0            0             1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's re-name the columns of data_reject to make the coding a bit more shorter to write\n",
    "#re-naming based from accepted column\n",
    "#Thus, rejected data will have same column name with accepted (for the ones that have similar meanings)\n",
    "data_reject=data_reject.rename(columns={\"Amount Requested\":\"loan_amnt\", \"Employment Length\": \"emp_length\", \"Debt-To-Income Ratio\":\"dti\"})\n",
    "#from the table, Employment Length is a categorical variable that contains different employment lengths \n",
    "#thus, I will make different columns for each category (One-hot encoding)\n",
    "#this allows categorical variable become indicator variable(#variable)\n",
    "dummies = pd.get_dummies(data_reject.emp_length, prefix='emp')\n",
    "#merge the dummy feature to the rejected\n",
    "data_reject = pd.merge(data_reject, dummies, how='left', left_index = True, right_index=True)\n",
    "#now drop the employment length(emp_length)\n",
    "data_reject.drop(['emp_length'], axis=1, inplace=True)\n",
    "#see if things are done correctly\n",
    "data_reject.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49f63f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#same 'dti' had different datatypes\n",
    "print(type(data_accept['dti'][1]) == type(data_reject['dti'][1]))\n",
    "#print(type(data_reject))\n",
    "data_reject['dti'] = data_reject['dti'].replace({'%':\"\"},regex=True)\n",
    "data_reject['dti'] = data_reject['dti']._convert(numeric=True)\n",
    "print(type(data_accept['dti'][1]) == type(data_reject['dti'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5d0e912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Percent Missing in Rejected\n",
      "loan_amnt                         0.000000\n",
      "Loan Title                        0.004713\n",
      "dti                               0.000000\n",
      "emp_1 year                        0.000000\n",
      "emp_10+ years                     0.000000\n",
      "emp_2 years                       0.000000\n",
      "emp_3 years                       0.000000\n",
      "emp_4 years                       0.000000\n",
      "emp_5 years                       0.000000\n",
      "emp_6 years                       0.000000\n",
      "emp_7 years                       0.000000\n",
      "emp_8 years                       0.000000\n",
      "emp_9 years                       0.000000\n",
      "emp_< 1 year                      0.000000\n"
     ]
    }
   ],
   "source": [
    "#Now check the missing rate again\n",
    "reject_missing = data_reject.isnull().sum()*100/len(data_reject) #percentage of missing data\n",
    "reject_missing_df = pd.DataFrame({'Percent Missing in Rejected':reject_missing})\n",
    "print(reject_missing_df)\n",
    "#Cool, now reject data has been finally cleaned to be used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dea80ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   loan_amnt    dti  emp_1 year  emp_10+ years  emp_2 years  emp_3 years  \\\n",
      "0     3600.0   5.91           0              1            0            0   \n",
      "1    24700.0  16.06           0              1            0            0   \n",
      "2    20000.0  10.78           0              1            0            0   \n",
      "3    35000.0  17.06           0              1            0            0   \n",
      "4    10400.0  25.37           0              0            0            1   \n",
      "\n",
      "   emp_4 years  emp_5 years  emp_6 years  emp_7 years  emp_8 years  \\\n",
      "0            0            0            0            0            0   \n",
      "1            0            0            0            0            0   \n",
      "2            0            0            0            0            0   \n",
      "3            0            0            0            0            0   \n",
      "4            0            0            0            0            0   \n",
      "\n",
      "   emp_9 years  emp_< 1 year  \n",
      "0            0             0  \n",
      "1            0             0  \n",
      "2            0             0  \n",
      "3            0             0  \n",
      "4            0             0  \n"
     ]
    }
   ],
   "source": [
    "#The thing is, some of the loan titles have erros as 'creditt card loan'\n",
    "#I still think it is important to have the loan title, but there are to much diverse reasons and my local has hard time using this to train the data. \n",
    "#But, in future, to use this, integer encoding-> onehot encoding is necessary But will generate 63~73k different columns for this.\n",
    "#Also, some of the columns, there are too much missing data. Things like 'settlement' have 98% data missing\n",
    "#So, I choose the data I want to work with: loan amount, employment year, debt to income ratio(dti)\n",
    "data_accept = data_accept[[\"loan_amnt\", \"dti\", \"emp_length\"]] #I thought total_pymnt was the total amount borrowed but it wasn't(some even had 0)\n",
    "#for i in data_accept.total_pymnt:\n",
    "#    if i == 0:\n",
    "#        print(0)\n",
    "#    else:\n",
    "#        pass\n",
    "data_reject.drop(['Loan Title'], axis=1, inplace=True)\n",
    "dummy = pd.get_dummies(data_accept.emp_length, prefix = 'emp')\n",
    "data_accept = pd.merge(data_accept, dummy, how='left', left_index = True, right_index =True)\n",
    "data_accept.drop(['emp_length'], axis=1, inplace=True)\n",
    "print(data_accept.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a352a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Percent Missing in Accepted\n",
      "loan_amnt                         0.001460\n",
      "dti                               0.077144\n",
      "emp_1 year                        0.000000\n",
      "emp_10+ years                     0.000000\n",
      "emp_2 years                       0.000000\n",
      "emp_3 years                       0.000000\n",
      "emp_4 years                       0.000000\n",
      "emp_5 years                       0.000000\n",
      "emp_6 years                       0.000000\n",
      "emp_7 years                       0.000000\n",
      "emp_8 years                       0.000000\n",
      "emp_9 years                       0.000000\n",
      "emp_< 1 year                      0.000000\n",
      "               Percent Missing in Rejected\n",
      "loan_amnt                              0.0\n",
      "dti                                    0.0\n",
      "emp_1 year                             0.0\n",
      "emp_10+ years                          0.0\n",
      "emp_2 years                            0.0\n",
      "emp_3 years                            0.0\n",
      "emp_4 years                            0.0\n",
      "emp_5 years                            0.0\n",
      "emp_6 years                            0.0\n",
      "emp_7 years                            0.0\n",
      "emp_8 years                            0.0\n",
      "emp_9 years                            0.0\n",
      "emp_< 1 year                           0.0\n"
     ]
    }
   ],
   "source": [
    "#check the missing rate just in case\n",
    "accepted_missing = data_accept.isnull().sum()*100/len(data_accept)\n",
    "accepted_missing_df = pd.DataFrame({'Percent Missing in Accepted':accepted_missing})\n",
    "print(accepted_missing_df)\n",
    "reject_missing = data_reject.isnull().sum()*100/len(data_reject) #percentage of missing data\n",
    "reject_missing_df = pd.DataFrame({'Percent Missing in Rejected':reject_missing})\n",
    "print(reject_missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db86062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09485844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of data left in accepted dataset after cleaning:  2258957\n",
      "amount of data left in rejected dataset after cleaning:  27648741\n",
      "   loan_amnt    dti  emp_1 year  emp_10+ years  emp_2 years  emp_3 years  \\\n",
      "0     3600.0   5.91           0              1            0            0   \n",
      "1    24700.0  16.06           0              1            0            0   \n",
      "2    20000.0  10.78           0              1            0            0   \n",
      "3    35000.0  17.06           0              1            0            0   \n",
      "4    10400.0  25.37           0              0            0            1   \n",
      "\n",
      "   emp_4 years  emp_5 years  emp_6 years  emp_7 years  emp_8 years  \\\n",
      "0            0            0            0            0            0   \n",
      "1            0            0            0            0            0   \n",
      "2            0            0            0            0            0   \n",
      "3            0            0            0            0            0   \n",
      "4            0            0            0            0            0   \n",
      "\n",
      "   emp_9 years  emp_< 1 year  loan_get  \n",
      "0            0             0         1  \n",
      "1            0             0         1  \n",
      "2            0             0         1  \n",
      "3            0             0         1  \n",
      "4            0             0         1  \n"
     ]
    }
   ],
   "source": [
    "#Drop the NAs\n",
    "#it is only the accepted dataset that has the NAs\n",
    "data_accept = data_accept.dropna()\n",
    "print(\"amount of data left in accepted dataset after cleaning: \", len(data_accept))\n",
    "print(\"amount of data left in rejected dataset after cleaning: \", len(data_reject))\n",
    "#now make a column that tells whether a person got payment or not\n",
    "#having 0 will mean the person is rejected\n",
    "data_reject['loan_get'] = [0 for i in range(len(data_reject))]\n",
    "#print(data_reject.head())\n",
    "data_accept['loan_get'] = [1 for i in range(len(data_accept))]\n",
    "#print(data_accept.head())\n",
    "#merge the two dataset (the rejected are 0 accepted are 1 with the columns)\n",
    "data = pd.concat([data_accept, data_reject])\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e036ade4",
   "metadata": {},
   "source": [
    "### After cleaning the data: Modeling (+ Explaining the extension)\n",
    "Now I have the cleaned data to train. I made a new column 'loan_get' to tell whether the borrower actually got the loan or not. The loan_amnt is the amount of money they got (if the loan_get = 1). [Optional part of the assignment]\n",
    "\n",
    "Here, we can solve problem in 2 ways. \n",
    "1. Tell whether this person is going to get the loan or not\n",
    "2. Tell how much this person is expected to get the loan if they can get the loan\n",
    "\n",
    "The data we have are supervised with the 'loan_get' variable, thus making a supervised learning methods as our choice. \n",
    "\n",
    "First one can be done by a classifier(logistic regression) while the second one can be done by a regression(linear regression). I will do a classifier with cross validations & different c values as an extension. Also, doing the linear regression will be another extension, which uses dti values and employment years to figureout how much can they get if they get their loan proposals accepted. \n",
    "\n",
    "- After reading the column label's meaning and during the process of data cleaning, I've felt the need of making a simple AI rather than something very complex. To have many more criteria to test out, it for sure may have higher accuracy, however, sometimes, simpler model works good enough (Occam's Razor). \n",
    "\n",
    "- So, I was thinking about specific variable 'employment year' and 'loan amount' to see what are the relationship between these variables and the acceptance for the loan. And by considering prospect theory, which people feel much less dramatic increase/decrease of gain/loss when it gets further from 0. (ex, 100 USD increase from 10 USD or 1M USD has different utility in people's feeling which depends on the base (10 vs 1M from this example))\n",
    "- However, I still wanted to chose something outside from the class while one variable (loan amount) has more of continuous characteristic and the other (employment year) has more of discrete/categorizing characteristics. So, that is why I chose mixed model 'Joint inidcator model' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cafed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before we train the model, we need to split the data and set up the environment\n",
    "#Set up the environment\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import sklearn.metrics as met\n",
    "\n",
    "#first, split the data\n",
    "train, test = train_test_split(data, test_size = 0.2, random_state=42) #data is huge\n",
    "variables = list(data.columns)\n",
    "x_vars = variables[:13]\n",
    "\n",
    "X_train = train[x_vars]\n",
    "y_train = train['loan_get']\n",
    "\n",
    "test_X = test[x_vars]\n",
    "test_y = test['loan_get']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f91e9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\green\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean cross validation score : 0.9311657563361238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\green\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\green\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean cross validation score : 0.9309854515545009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\green\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean cross validation score : 0.9311892452753201\n",
      "mean cross validation score : 0.9311732376886435\n",
      "mean cross validation score : 0.9311732376886435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\green\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean cross validation score : 0.9286932743343141\n",
      "[0.9311657563361238, 0.9309854515545009, 0.9311892452753201, 0.9311732376886435, 0.9311732376886435, 0.9286932743343141]\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression \n",
    "#regr = linear_model.LogisticRegression()\n",
    "#In Logistic Regression there is a problem with overfitting. \n",
    "#according to https://realpython.com/logistic-regression-python/#multi-variate-logistic-regression\n",
    "#Regularization can possibly reduce or penalize the complexity of the model. \n",
    "#Higher C value means higher regulation = put more weight with the training data rather than panalizing it\n",
    "c = [0.1, 0.5, 1,2, 5, 10] #somehow 1, 2, and 100 are giving me nan\n",
    "best_c = []\n",
    "for i in c:\n",
    "    log_reg = linear_model.LogisticRegression(C = i, solver = 'lbfgs')\n",
    "    #something extra to do ()\n",
    "    accuracy_crossval = np.array(cross_val_score(log_reg, X_train, y_train, cv = 5)).mean()\n",
    "    print('mean cross validation score :', accuracy_crossval)\n",
    "    #performance measure\n",
    "    best_c.append(accuracy_crossval)\n",
    "\n",
    "print(best_c)   \n",
    "#so, it seems that C = 0.5 has the highest cross validation mean score. \n",
    "#But others really have similar accuracy by 0.5% differences between the worst and the best\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febd2b9f",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76108b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\green\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score :  0.9235141786228964\n",
      "coeffs:  [[ 2.11343078e-05 -3.37065578e-04  6.42535023e-02  4.98211344e-01\n",
      "   1.18163721e-01  1.04779275e-01  8.16041575e-02 -2.57279290e-01\n",
      "   6.54850830e-02  6.04013452e-02  5.88229615e-02  5.18678690e-02\n",
      "  -2.57051081e+00]] ,  [-1.75669943]\n",
      "precision score :  0.0\n",
      "recall : 0.0\n",
      "f1 score : 0.0\n"
     ]
    }
   ],
   "source": [
    "#evaluating one of the results\n",
    "log_reg = linear_model.LogisticRegression(C=1, solver = 'lbfgs').fit(X_train, y_train)\n",
    "accuracy_crossval = np.array(cross_val_score(log_reg, X_train, y_train, cv = 5)).mean()\n",
    "prediction = log_reg.predict(test_X)\n",
    "accuracy = met.accuracy_score(test_y, prediction)\n",
    "print(\"accuracy score : \", accuracy)\n",
    "print(\"coeffs: \", log_reg.coef_, ', ',log_reg.intercept_)\n",
    "print('precision score : ', met.precision_score(test_y,prediction))\n",
    "print('recall :', met.recall_score(test_y, prediction))\n",
    "print('f1 score :', met.f1_score(test_y, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bee944e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5524037,    5111],\n",
       "       [ 452392,       0]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"confusion matrix: \")\n",
    "met.confusion_matrix(test_y, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cb366b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            dti  emp_1 year  emp_10+ years  emp_2 years  emp_3 years  \\\n",
      "347953    10.26           0              0            0            0   \n",
      "2189888    4.74           0              0            0            0   \n",
      "19236929  11.32           0              0            0            0   \n",
      "2448190   -1.00           0              0            0            0   \n",
      "26522277  10.94           0              0            0            0   \n",
      "\n",
      "          emp_4 years  emp_5 years  emp_6 years  emp_7 years  emp_8 years  \\\n",
      "347953              0            0            0            0            0   \n",
      "2189888             0            0            0            0            0   \n",
      "19236929            0            0            0            0            0   \n",
      "2448190             0            0            0            0            0   \n",
      "26522277            0            0            0            0            0   \n",
      "\n",
      "          emp_9 years  emp_< 1 year  \n",
      "347953              0             1  \n",
      "2189888             0             1  \n",
      "19236929            0             1  \n",
      "2448190             0             1  \n",
      "26522277            0             1  \n",
      "           dti  emp_1 year  emp_10+ years  emp_2 years  emp_3 years  \\\n",
      "26042303  4.95           0              0            0            0   \n",
      "21523520  0.00           0              0            0            0   \n",
      "2283758   8.83           0              0            0            0   \n",
      "7888527   0.68           0              0            0            0   \n",
      "2579023   7.68           0              0            0            0   \n",
      "\n",
      "          emp_4 years  emp_5 years  emp_6 years  emp_7 years  emp_8 years  \\\n",
      "26042303            0            0            0            0            0   \n",
      "21523520            0            0            0            0            0   \n",
      "2283758             0            0            0            0            0   \n",
      "7888527             0            0            0            0            0   \n",
      "2579023             0            0            0            0            0   \n",
      "\n",
      "          emp_9 years  emp_< 1 year  \n",
      "26042303            0             1  \n",
      "21523520            0             1  \n",
      "2283758             0             1  \n",
      "7888527             0             1  \n",
      "2579023             0             0  \n",
      "347953       1000.0\n",
      "2189888     10000.0\n",
      "19236929    23000.0\n",
      "2448190     30000.0\n",
      "26522277     3000.0\n",
      "Name: loan_amnt, dtype: float64\n",
      "26042303    10000.0\n",
      "21523520     5000.0\n",
      "2283758     10000.0\n",
      "7888527      3000.0\n",
      "2579023      3500.0\n",
      "Name: loan_amnt, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Linear regression: predicting the amount of loan they can get based from dti and employment \n",
    "variables = list(data.columns)\n",
    "x_vars = variables[1:13]\n",
    "X = data[x_vars]\n",
    "y = data['loan_amnt']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "prediction = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6c746e86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coeffs:  [4.18449665e-04 1.27374562e+02 4.85169837e+03 1.89273505e+03\n",
      " 1.93891877e+03 2.27142323e+03 2.24359191e+02 3.40521249e+03\n",
      " 3.91783840e+03 3.74155930e+03 3.45610791e+03 1.99467613e+03] ,  11383.448976762373\n",
      "MSE :  212719157.15092295\n",
      "median absolute error :  8378.12722046813\n",
      "r2:  0.0037672345762671533\n",
      "mean absolute error:  9292.046696446623\n"
     ]
    }
   ],
   "source": [
    "#Linear regression performance measure\n",
    "print(\"coeffs: \", regr.coef_, ', ',regr.intercept_)\n",
    "print(\"MSE : \", met.mean_squared_error(y_test, prediction))\n",
    "print(\"median absolute error : \", met.median_absolute_error(y_test, prediction))\n",
    "print(\"r2: \", met.r2_score(y_test, prediction))\n",
    "print(\"mean absolute error: \", met.mean_absolute_error(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ced353",
   "metadata": {},
   "source": [
    "### Summary\n",
    "Variables Included : dti, employment length, loan amount(requested for rejected people/requested and recieved for approved people)\n",
    "- Reason: The variable that were easy to convert & had small loss of information\n",
    "Cleaning of the data & transformations: \n",
    "1. Dropping redundant columns\n",
    "2. Dropping columns that has too much NAs\n",
    "3. Onehot coding for employment length(from categorical variable to indicator)\n",
    "4. Make accepted and rejected data to have same data types for each columns\n",
    "\n",
    "ML models of choice: Logistic Regression(classification of getting the money or not), Linear Regression(estimating of how much money they can recieve depending on dti and employment length)\n",
    "\n",
    "Settings : C value(regulation of how strong the training data is and how strong are the panalizing of training data)\n",
    "\n",
    "Specific methods: cross-validation (5 folds)\n",
    "\n",
    "Model Performance:\n",
    "- Logistic Regression: Strange performance was found, having 0 as f1\n",
    "    - accuracy score :  0.9235141786228964\n",
    "    - coeffs:  [[ 2.11347307e-05 -3.36742421e-04  6.42533329e-02  4.98210030e-011.18163409e-01  1.04778998e-01  8.16039424e-02 -2.57278613e-01 6.54849104e-02  6.04011861e-02  5.88228065e-02  5.18677323e-02  -2.57050403e+00]] , [-1.7566948]\n",
    "    - precision score :  0.0\n",
    "    - recall : 0.0\n",
    "    - f1 score : 0.0\n",
    "- Linear Regression\n",
    "   - coeffs:  [4.18449665e-04 1.27374562e+02 4.85169837e+03 1.89273505e+031.93891877e+03 2.27142323e+03 2.24359191e+02 3.40521249e+03 3.91783840e+03 3.74155930e+03 3.45610791e+03 1.99467613e+03] ,11383.4489767623734\n",
    "   \n",
    "  - MSE :  212719157.15092295\n",
    "  - median absolute error :  8378.12722046813\n",
    "  - r2:  0.0037672345762671533\n",
    "  - mean absolute error:  9292.046696446623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edca7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
