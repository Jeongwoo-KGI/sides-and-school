{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df17cd6e",
   "metadata": {},
   "source": [
    "## Preclass work for Session 3: Ensuring quality when training\n",
    "\n",
    "Class notes of JWP on session 3\n",
    "[https://jeongwoopark.notion.site/Ensuring-Quality-when-Training-0301cbfed4df491bb01f75f67d183fb6]\n",
    "\n",
    "preclasswork descriptions and variable explanations in [https://github.com/minerva-university/cs156/tree/master/session03]\n",
    "\n",
    "### Task 1: Regression with Facebook data\n",
    "\n",
    "data retrieved from [https://docs.google.com/spreadsheets/d/1B2xkgo7clRcNRbIjBZT4MaleCxm6vjeZa5rhoAANo9E/edit#gid=1103908018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d58cf14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the environment for task 1 (regression)\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import pystan\n",
    "import scipy.stats as sts\n",
    "from scipy import optimize\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9a1b133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_followers   type  category  month  weekday  hour  paid  comment  \\\n",
      "0           124050  Photo         3      6        4    17     1        3   \n",
      "1           132556  Photo         2      8        3    24     0       11   \n",
      "2            92786  Photo         2      2        6    17     1        2   \n",
      "3           135632  Photo         1      9        2     1     0        2   \n",
      "4           139540   Link         1     12        3    17     1        7   \n",
      "\n",
      "   like  share  \n",
      "0    77     16  \n",
      "1   313     50  \n",
      "2   145     39  \n",
      "3   299     49  \n",
      "4   229     21  \n",
      "<class 'numpy.int64'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\green\\Downloads\\facebook_train.csv')\n",
    "print(data.head())\n",
    "\n",
    "total_followers = data.total_followers\n",
    "types = data.type\n",
    "category = data.category\n",
    "month = data.month\n",
    "weekday = data.weekday\n",
    "hour = data.hour\n",
    "paid = data.paid\n",
    "comment = data.comment\n",
    "like = data.like\n",
    "share = data.share\n",
    "\n",
    "print(type(share[0]))\n",
    "print(type(types[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb3bc30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                comment   R-squared:                       0.787\n",
      "Model:                            OLS   Adj. R-squared:                  0.783\n",
      "Method:                 Least Squares   F-statistic:                     179.5\n",
      "Date:                Mon, 17 Jan 2022   Prob (F-statistic):          2.37e-125\n",
      "Time:                        18:05:49   Log-Likelihood:                -1580.6\n",
      "No. Observations:                 397   AIC:                             3179.\n",
      "Df Residuals:                     388   BIC:                             3215.\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.3052      0.031      9.992      0.000       0.245       0.365\n",
      "x2             0.0215      0.004      5.279      0.000       0.013       0.029\n",
      "x3            -0.0599      0.083     -0.724      0.470      -0.223       0.103\n",
      "x4             0.1565      0.339      0.461      0.645      -0.510       0.823\n",
      "x5            -3.5394      0.787     -4.497      0.000      -5.087      -1.992\n",
      "x6             0.0002      0.000      1.845      0.066   -1.45e-05       0.000\n",
      "x7            -1.1296      1.484     -0.761      0.447      -4.046       1.787\n",
      "x8            -1.0402      0.593     -1.754      0.080      -2.206       0.126\n",
      "const        -18.1011     10.913     -1.659      0.098     -39.557       3.355\n",
      "==============================================================================\n",
      "Omnibus:                      263.478   Durbin-Watson:                   1.865\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5106.107\n",
      "Skew:                           2.477   Prob(JB):                         0.00\n",
      "Kurtosis:                      19.856   Cond. No.                     2.07e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.07e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   like   R-squared:                       0.856\n",
      "Model:                            OLS   Adj. R-squared:                  0.853\n",
      "Method:                 Least Squares   F-statistic:                     289.3\n",
      "Date:                Mon, 17 Jan 2022   Prob (F-statistic):          2.32e-158\n",
      "Time:                        18:05:49   Log-Likelihood:                -2569.4\n",
      "No. Observations:                 397   AIC:                             5157.\n",
      "Df Residuals:                     388   BIC:                             5193.\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             5.4740      0.306     17.895      0.000       4.873       6.075\n",
      "x2             3.1244      0.592      5.279      0.000       1.961       4.288\n",
      "x3            -0.4103      1.000     -0.410      0.682      -2.377       1.557\n",
      "x4            -4.4870      4.088     -1.098      0.273     -12.524       3.550\n",
      "x5            10.4237      9.729      1.071      0.285      -8.704      29.551\n",
      "x6             0.0005      0.001      0.315      0.753      -0.002       0.003\n",
      "x7            41.1765     17.796      2.314      0.021       6.189      76.164\n",
      "x8             2.8158      7.185      0.392      0.695     -11.310      16.942\n",
      "const        -72.2575    132.118     -0.547      0.585    -332.015     187.500\n",
      "==============================================================================\n",
      "Omnibus:                      356.316   Durbin-Watson:                   1.880\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            10528.884\n",
      "Skew:                           3.724   Prob(JB):                         0.00\n",
      "Kurtosis:                      27.105   Cond. No.                     2.07e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.07e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  share   R-squared:                       0.877\n",
      "Model:                            OLS   Adj. R-squared:                  0.875\n",
      "Method:                 Least Squares   F-statistic:                     346.2\n",
      "Date:                Mon, 17 Jan 2022   Prob (F-statistic):          1.90e-171\n",
      "Time:                        18:05:49   Log-Likelihood:                -1736.9\n",
      "No. Observations:                 397   AIC:                             3492.\n",
      "Df Residuals:                     388   BIC:                             3528.\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.0826      0.005     17.895      0.000       0.074       0.092\n",
      "x2             0.6707      0.067      9.992      0.000       0.539       0.803\n",
      "x3             0.1130      0.123      0.920      0.358      -0.128       0.354\n",
      "x4             0.5288      0.502      1.053      0.293      -0.459       1.516\n",
      "x5             3.5733      1.183      3.020      0.003       1.247       5.899\n",
      "x6            -0.0002      0.000     -1.184      0.237      -0.001       0.000\n",
      "x7            -1.8168      2.199     -0.826      0.409      -6.140       2.507\n",
      "x8             0.4677      0.882      0.530      0.596      -1.267       2.203\n",
      "const         21.2588     16.200      1.312      0.190     -10.592      53.109\n",
      "==============================================================================\n",
      "Omnibus:                       86.770   Durbin-Watson:                   1.820\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1839.853\n",
      "Skew:                           0.199   Prob(JB):                         0.00\n",
      "Kurtosis:                      13.539   Cond. No.                     2.07e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.07e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "#Regression of comments\n",
    "y_1 = comment\n",
    "x_1 = [month,paid, total_followers, category, weekday, hour, like, share]\n",
    "\n",
    "def reg(y, x):\n",
    "    ones = np.ones(len(x[0]))\n",
    "    X = sm.add_constant(np.column_stack((x[0], ones)))\n",
    "    for ele in x[1:]:\n",
    "        X = sm.add_constant(np.column_stack((ele, X)))\n",
    "    results = sm.OLS(y, X).fit()\n",
    "    return results\n",
    "\n",
    "print(reg(y_1, x_1).summary())\n",
    "\n",
    "#regression of like\n",
    "x_2 = [month,paid, total_followers, category, weekday, hour,comment, share]\n",
    "y_2 = like\n",
    "print(reg(y_2,x_2).summary())\n",
    "\n",
    "#regression of shares\n",
    "x_3 = [month,paid, total_followers, category, weekday, hour,comment, like]\n",
    "y_3 = share\n",
    "\n",
    "print(reg(y_3,x_3).summary())\n",
    "#without categorical (discrete) variables with less than 3 values\n",
    "#x_3 = [month, total_followers, weekday, hour,comment, like]\n",
    "#y_3 = share\n",
    "\n",
    "#print(reg(y_3,x_3).summary())\n",
    "##suprisingly, this makes regression have less r^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930f29bd",
   "metadata": {},
   "source": [
    "So far, I've tried to make a regression and played around with it to continue and not continue some variables for the 4th regression. However, it seems not having discrete variable does not make r^2 go up even though those discrete variables have less than 3 values. \n",
    "\n",
    "This might mean (just a guess) that the categorical data with less than 3 values are highly related with the variables and thus giving a slight rise on r^2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfe5a83d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'RegressionResultsWrapper' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27656/214945918.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\green\\Downloads\\facebook_test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'RegressionResultsWrapper' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "data_test = pd.read_csv(r'C:\\Users\\green\\Downloads\\facebook_test.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11e5a43",
   "metadata": {},
   "source": [
    "### Task 2: Casualty Classification\n",
    "\n",
    "data retrieved from [https://docs.google.com/spreadsheets/d/1lOt3ktFmX0fiWa89dLUiKfv1zoYjyI23zo3Ntb6HzhQ/edit#gid=952175914]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ee0c4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  casualty_class  gender age  severe pedestrian_location pedestrian_movement  \\\n",
      "0      passenger  female  33   False                 NaN                 NaN   \n",
      "1      passenger  female  20   False                 NaN                 NaN   \n",
      "2      passenger    male  52   False                 NaN                 NaN   \n",
      "3      passenger  female  17   False                 NaN                 NaN   \n",
      "4      passenger  female  20   False                 NaN                 NaN   \n",
      "\n",
      "       travel  year  \n",
      "0   motorbike  2007  \n",
      "1         car  2005  \n",
      "2         car  2006  \n",
      "3  pedestrian  2012  \n",
      "4   motorbike  2010  \n"
     ]
    }
   ],
   "source": [
    "task2 = pd.read_csv(r'C:\\Users\\green\\Downloads\\casualty_train.csv')\n",
    "print(task2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186d52af",
   "metadata": {},
   "source": [
    "Pedestrian_location and pedestrian movements have too much diversity to classify as well as having too much N/A. So, I am dropping it\n",
    "\n",
    "Also, the year has to do nothing with the injuries. There can be a difference by change in law, however, that is more of previous/post legistration rather than specific year to do with the severeness of the injury. So, I am not using the variable for classification. \n",
    "\n",
    "casualty_class, age, gender, travel has a lot to do with the results. Because of difference in speed, force, protection, and body composition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e10081a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232835\n",
      "(232835,)\n",
      "(232835,)\n",
      "(232835,)\n",
      "(232835,)\n"
     ]
    }
   ],
   "source": [
    "casualty_class = task2['casualty_class']\n",
    "gender = task2['gender']\n",
    "age = task2['age']\n",
    "travel = task2['travel']\n",
    "severe = task2['severe']\n",
    "\n",
    "print(len(travel))\n",
    "print(gender.shape)\n",
    "print(age.shape)\n",
    "print(travel.shape)\n",
    "print(severe.shape)\n",
    "\n",
    "data2 = np.array([casualty_class, gender, age, travel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f5fe70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the environment\n",
    "import pprint\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d3dc39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\green\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\green\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\green\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"C:\\Users\\green\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 400, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\", multi_output=True)\n",
      "  File \"C:\\Users\\green\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 576, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\green\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 956, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"C:\\Users\\green\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 738, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"C:\\Users\\green\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 1993, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'Unknown'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Unknown'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27656/3412086132.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'f1_macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainLabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestLabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"requires_y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNeighborsBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    574\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 576\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 956\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m    957\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    736\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 738\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    739\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m                 raise ValueError(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1992\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNpDtype\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1993\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1995\u001b[0m     def __array_wrap__(\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Unknown'"
     ]
    }
   ],
   "source": [
    "#In the future, I gotta use kfold after the class to make the idea a bit more concrete to get higher accuracy\n",
    "X = task2.drop(columns = ['year', 'pedestrian_movement', 'pedestrian_location'])\n",
    "y = severe\n",
    "trainData,testData,trainLabel,testLabel = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors = 482) #rule of thumb is data squared\n",
    "from sklearn import metrics\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring = 'f1_macro')\n",
    "model.fit(trainData,trainLabel)\n",
    "predictions = model.predict(testData)\n",
    "print(classification_report(testLabel, predictions))\n",
    "\n",
    "#why is it not working???\n",
    "newdata = pd.read_csv(r'C:\\Users\\green\\Downloads\\casualty_test.csv')\n",
    "predictions = model.predict(newdata)\n",
    "print(classification_report(testLabel, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f1f24f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
