{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCW for Session 8 of CS156"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing a PCA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n",
      "'wget'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n",
      "'unzip'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n",
      "'unzip'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n",
      "'rm'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PIL import Image\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from resizeimage import resizeimage\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.transform import resize\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "#first get the images of clothings \n",
    "male_clothes_data = glob(r'male-clothing\\*')\n",
    "jerseys_data = glob(r'jersey\\*')\n",
    "\n",
    "male_clothes = []\n",
    "jerseys = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def extract_feature(dir_path):\n",
    "    img = mpimg.imread(dir_path)\n",
    "    img = img / 255.0  # normalize pixel values\n",
    "    img = resize(img, (128, 128, 3))  # convert all images to (128x128x3)\n",
    "    img = np.reshape(img, (128, 384))\n",
    "    return img\n",
    "\n",
    "male_clothes = [extract_feature(filename) for filename in male_clothes_data]\n",
    "jerseys = [extract_feature(filename) for filename in jerseys_data]\n",
    "print(len(jerseys))\n",
    "print(len(male_clothes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,) (0, 1)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20624/2503643739.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m gridspec_kw=dict(hspace=0.01, wspace=0.01))\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gray\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 100 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#recize the image so that we can use them to train. \n",
    "for path in male_clothes_data:\n",
    "    # open it as a read file in binary mode\n",
    "    with open(path, 'r+b') as f:\n",
    "        # open it as an image\n",
    "        with Image.open(f) as image:\n",
    "            # convert image to RGB\n",
    "            if image.mode != \"RGB\":\n",
    "                image = image.convert('RGB')\n",
    "            # image = image.convert('L')\n",
    "            # resize the image to be more manageable\n",
    "            cover = resizeimage.resize_cover(image, [20, 20])\n",
    "            # flatten the matrix to an array and append it to all flattened images\n",
    "            male_clothes.append(np.array(cover).flatten())\n",
    "\n",
    "for path in jerseys_data:\n",
    "    # open it as a read file in binary mode\n",
    "    with open(path, 'r+b') as f:\n",
    "        # open it as an image\n",
    "        with Image.open(f) as image:\n",
    "            # convert image to RGB\n",
    "            if image.mode != \"RGB\":\n",
    "                image = image.convert('RGB')\n",
    "            # image = image.convert('L')\n",
    "            # resize the image to be more manageable\n",
    "            cover = resizeimage.resize_cover(image, [20, 20])\n",
    "            # flatten the matrix to an array and append it to all flattened images\n",
    "            jerseys.append(np.array(cover).flatten())\n",
    "                 \n",
    "male_clothes = np.asarray(male_clothes)\n",
    "jerseys = np.asarray(jerseys)\n",
    "\n",
    "#prepare the data to be trained in variable X and Y\n",
    "X = np.concatenate((male_clothes, jerseys))\n",
    "Y = np.concatenate((np.zeros(len(male_clothes)), np.ones(len(jerseys)))).reshape(-1, 1)\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "#first, show the data that are going to be used for making PCA\n",
    "fig, axes = plt.subplots(10,10,figsize=(9,9),\n",
    "subplot_kw={'xticks':[], 'yticks':[]},\n",
    "gridspec_kw=dict(hspace=0.01, wspace=0.01))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(X[i].reshape(20,20,3), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20484/315422089.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecomposition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mrescaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mscaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrescaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    380\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \"\"\"\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    428\u001b[0m             )\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m         X = self._validate_data(\n\u001b[0m\u001b[0;32m    431\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    759\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    762\u001b[0m                     \u001b[1;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "#fit the PCA\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "pca = decomposition.PCA()\n",
    "pca.fit(X)\n",
    "rescaled = pca.transform(X)\n",
    "scaled = pca.inverse_transform(rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to operator (Temp/ipykernel_5168/2361098697.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\green\\AppData\\Local\\Temp/ipykernel_5168/2361098697.py\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    X_r^2 = LDA.fit(X,y).transform(X)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m cannot assign to operator\n"
     ]
    }
   ],
   "source": [
    "#PCW8 LDA(Linear Discriminant Analysis)\n",
    "x = jerseys + male_clothes\n",
    "Y = [0 for i in range(len(jerseys))] + [1 for i in range(len(male_clothes))]\n",
    "LDA = LinearDiscriminatAnalysis()\n",
    "X = x\n",
    "y = Y\n",
    "X_r^2 = LDA.fit(X,y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0 for i in range(5)] + [1 for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
